import os
import logging
import json
import time
from datetime import datetime
from typing import Dict, List, Optional, Union

from fastapi import FastAPI, HTTPException, Depends, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv

# í™˜ê²½ ì„¤ì • ë¡œë“œ
if os.getenv("RAILWAY_ENVIRONMENT") != "true":
    load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("chatbot_service")

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="Chatbot Service",
    description="LangChainì„ ì‚¬ìš©í•œ AI ì±„íŒ… ì„œë¹„ìŠ¤",
    version="1.0.0",
    docs_url="/docs"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        os.getenv("FRONTEND_ORIGIN", "http://localhost:3000"),
        os.getenv("GATEWAY_ORIGIN", "http://localhost:8080"),
    ],
    allow_origin_regex=r"https://.*\.railway\.app",
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# JWT Bearer í† í° ìŠ¤í‚¤ë§ˆ  
security = HTTPBearer()

# ===== Pydantic ëª¨ë¸ë“¤ =====
class ChatMessageRequest(BaseModel):
    message: str
    session_id: Optional[int] = None
    context: Optional[dict] = None

class LangChainResponse(BaseModel):
    response: str
    session_id: int
    message_id: int
    tokens_used: Optional[int] = None
    processing_time: Optional[float] = None

class ChatSessionResponse(BaseModel):
    id: int
    user_id: int
    session_title: Optional[str]
    created_at: datetime
    is_active: bool

# ===== ê°„ë‹¨í•œ LangChain ì„œë¹„ìŠ¤ =====
class SimpleLangChainService:
    def __init__(self):
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        logger.info(f"ğŸ”‘ OpenAI API Key: {'ì„¤ì •ë¨' if self.openai_api_key else 'ì„¤ì • ì•ˆë¨ (ë”ë¯¸ ëª¨ë“œ)'}")
    
    async def generate_response(self, message: str, chat_history: Optional[List] = None, context: Optional[Dict] = None) -> Dict:
        """AI ì‘ë‹µ ìƒì„±"""
        start_time = time.time()
        
        try:
            if self.openai_api_key:
                # TODO: ì‹¤ì œ OpenAI API í˜¸ì¶œ
                response = await self._generate_openai_response(message, chat_history, context)
            else:
                # ë”ë¯¸ ì‘ë‹µ
                response = self._generate_dummy_response(message)
            
            processing_time = time.time() - start_time
            
            return {
                "response": response,
                "tokens_used": 0,  # TODO: ì‹¤ì œ í† í° ìˆ˜ ê³„ì‚°
                "processing_time": processing_time,
                "success": True
            }
            
        except Exception as e:
            logger.error(f"AI ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            processing_time = time.time() - start_time
            
            return {
                "response": "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ì„œë¹„ìŠ¤ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "tokens_used": 0,
                "processing_time": processing_time,
                "success": False,
                "error": str(e)
            }
    
    def _generate_dummy_response(self, message: str) -> str:
        """ë”ë¯¸ ì‘ë‹µ ìƒì„± (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)"""
        dummy_responses = {
            "ì•ˆë…•": "ì•ˆë…•í•˜ì„¸ìš”! ì¤‘ì†Œê¸°ì—… ì§„ë‹¨ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?",
            "ì¬ë¬´": "ì¬ë¬´ ìƒíƒœë¥¼ ë¶„ì„í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ë§¤ì¶œ, ë¹„ìš©, í˜„ê¸ˆíë¦„ ë“±ì˜ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë” ì •í™•í•œ ì§„ë‹¨ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
            "ìš´ì˜": "ìš´ì˜ íš¨ìœ¨ì„±ì„ ê°œì„ í•˜ê¸° ìœ„í•´ í”„ë¡œì„¸ìŠ¤ ìµœì í™”, ì¸ë ¥ ê´€ë¦¬, ê¸°ìˆ  ë„ì… ë“±ì„ ê²€í† í•´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.",
            "ë§ˆì¼€íŒ…": "ë§ˆì¼€íŒ… ì „ëµìœ¼ë¡œëŠ” ë””ì§€í„¸ ë§ˆì¼€íŒ… ê°•í™”, ê³ ê° ì„¸ë¶„í™”, ë¸Œëœë“œ í¬ì§€ì…”ë‹ ë“±ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.",
            "í‰ê°€": "ê¸°ì—… í‰ê°€ë¥¼ ìœ„í•´ì„œëŠ” ì¬ë¬´ì œí‘œ, ì‚¬ì—…ê³„íšì„œ, ì‹œì¥ ë¶„ì„ ìë£Œ ë“±ì´ í•„ìš”í•©ë‹ˆë‹¤. ì–´ë–¤ ë¶€ë¶„ì„ ì¤‘ì ì ìœ¼ë¡œ ì‚´í´ë³´ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
            "ê°œì„ ": "ê°œì„  ë°©ì•ˆì„ ì œì‹œí•˜ê¸° ìœ„í•´ í˜„ì¬ ê²ªê³  ìˆëŠ” ë¬¸ì œì ì´ë‚˜ ëª©í‘œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì„¸ìš”."
        }
        
        for keyword, response in dummy_responses.items():
            if keyword in message:
                return response
        
        return f"'{message}'ì— ëŒ€í•´ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤. ì¤‘ì†Œê¸°ì—… ì§„ë‹¨ ê´€ë ¨í•˜ì—¬ ì¬ë¬´, ìš´ì˜, ë§ˆì¼€íŒ…, ì¸ì‚¬ ë“± ì–´ë–¤ ë¶„ì•¼ì— ëŒ€í•´ ë” ìì„¸íˆ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"
    
    async def _generate_openai_response(self, message: str, chat_history: Optional[List] = None, context: Optional[Dict] = None) -> str:
        """OpenAI APIë¥¼ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„± (í–¥í›„ êµ¬í˜„)"""
        # TODO: ì‹¤ì œ OpenAI API í˜¸ì¶œ êµ¬í˜„
        return "ì‹¤ì œ OpenAI API ì‘ë‹µ (êµ¬í˜„ ì˜ˆì •)"

# LangChain ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
langchain_service = SimpleLangChainService()

# ===== API ì—”ë“œí¬ì¸íŠ¸ë“¤ =====

@app.post("/api/v1/chat/send", response_model=LangChainResponse, summary="ë©”ì‹œì§€ ì „ì†¡")
async def send_message(
    message_request: ChatMessageRequest
    # credentials: HTTPAuthorizationCredentials = Depends(security)  # ì„ì‹œ ë¹„í™œì„±í™”
):
    """AI ì±„íŒ…ë´‡ì—ê²Œ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ê³  ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤."""
    try:
        logger.info(f"ğŸ¤– ë©”ì‹œì§€ ìˆ˜ì‹ : {message_request.message}")
        
        # ê°„ë‹¨í•œ ì‚¬ìš©ì ID (ì‹¤ì œë¡œëŠ” JWTì—ì„œ ì¶”ì¶œ)
        user_id = 1
        
        # ì„¸ì…˜ ID ìƒì„± ë˜ëŠ” ì‚¬ìš©
        session_id = message_request.session_id or int(time.time())
        
        # ë”ë¯¸ ì‘ë‹µìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        dummy_response = f"í…ŒìŠ¤íŠ¸ ì‘ë‹µ: '{message_request.message}'ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤."
        
        logger.info(f"âœ… ë”ë¯¸ ì‘ë‹µ ìƒì„± ì™„ë£Œ: {dummy_response}")
        
        return LangChainResponse(
            response=dummy_response,
            session_id=session_id,
            message_id=int(time.time()),  # ì„ì‹œ message_id
            tokens_used=0,
            processing_time=0.1
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        logger.error(f"âŒ ì—ëŸ¬ íƒ€ì…: {type(e)}")
        logger.error(f"âŒ ì—ëŸ¬ ìƒì„¸: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@app.get("/api/v1/chat/sessions", response_model=List[ChatSessionResponse], summary="ì±„íŒ… ì„¸ì…˜ ëª©ë¡")
async def get_chat_sessions(
    credentials: HTTPAuthorizationCredentials = Depends(security)
):
    """ì‚¬ìš©ìì˜ ì±„íŒ… ì„¸ì…˜ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    # TODO: ì‹¤ì œ DBì—ì„œ ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ
    return [
        ChatSessionResponse(
            id=1,
            user_id=1,
            session_title="ê¸°ì—… ì§„ë‹¨ ìƒë‹´",
            created_at=datetime.now(),
            is_active=True
        )
    ]

@app.delete("/api/v1/chat/sessions/{session_id}", summary="ì±„íŒ… ì„¸ì…˜ ì‚­ì œ")
async def delete_chat_session(
    session_id: int,
    credentials: HTTPAuthorizationCredentials = Depends(security)
):
    """ì±„íŒ… ì„¸ì…˜ì„ ì‚­ì œí•©ë‹ˆë‹¤."""
    logger.info(f"ğŸ—‘ï¸ ì„¸ì…˜ ì‚­ì œ ìš”ì²­: {session_id}")
    return {"message": "ì„¸ì…˜ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤", "session_id": session_id}

# ===== ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸ë“¤ =====

@app.get("/", include_in_schema=False)
async def root():
    return {
        "service": "Chatbot Service",
        "version": "1.0.0",
        "status": "running",
        "features": ["LangChain", "AI Chat", "Enterprise Diagnosis"],
        "endpoints": {
            "docs": "/docs",
            "health": "/health",
            "send_message": "/api/v1/chat/send",
            "sessions": "/api/v1/chat/sessions"
        }
    }

@app.get("/health", include_in_schema=False)
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    openai_status = "configured" if os.getenv("OPENAI_API_KEY") else "dummy_mode"
    database_status = "configured" if os.getenv("DATABASE_URL") else "not_configured"
    
    return {
        "status": "healthy",
        "service": "Chatbot Service",
        "version": "1.0.0",
        "openai": openai_status,
        "database": database_status,
        "features": {
            "langchain": True,
            "chat_responses": True,
            "dummy_responses": True,
            "enterprise_diagnosis": True
        }
    }

# ë¡œì»¬ ì‹¤í–‰ìš©
if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8003))
    logger.info(f"ğŸš€ Chatbot Service ì‹œì‘ (í¬íŠ¸: {port})")
    uvicorn.run("main:app", host="0.0.0.0", port=port, reload=True)